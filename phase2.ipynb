{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Phase 2\n",
    "\n",
    "## Data Collection and Cleaning\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import os\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "#import the three libraries of assembled movie metdata\n",
    "from collections import defaultdict\n",
    "from drama_movies import drama_movies\n",
    "from crime_film_noir import crime_movies\n",
    "from thriller_movies import thriller_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks to see if a given line follows the same format as a new character tag\n",
    "def check_if_character(line, punct_set):\n",
    "    if \"(\" in line:\n",
    "        line=line[:line.index(\"(\")].strip()\n",
    "    if \"{\" in line:\n",
    "        line=line[:line.index(\"{\")].strip()\n",
    "    if '[' in line:\n",
    "        line=line[:line.index('[')].strip()\n",
    "    if \"/\" in line:\n",
    "            line=line[:line.index('/')-1].strip()\n",
    "    if line.upper()==line and line.isupper() and line[-1] not in punct_set and line.count(' ')<4:\n",
    "        \n",
    "        return True, line\n",
    "    else:\n",
    "        return False, \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks to see if this character is either one of the important characters in the story or a villain\n",
    "def check_if_acceptable_character(this_character, acceptable_characters):\n",
    "    if this_character in acceptable_characters:\n",
    "        return True\n",
    "    else:\n",
    "        cleaner=str.maketrans('','',string.punctuation)\n",
    "        this_character=this_character.translate(cleaner)\n",
    "        for character in acceptable_characters:\n",
    "            if character in this_character or this_character in character:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"takes the movie metadata, reads each script, and returns a list made of dictionaries corresponding to each new character that's been labeled as important. The list and dictionaries follow the format below\n",
    "\n",
    "[{\"character\": \"the name of the character\", \"movie_title\": \"the title of the movie they're in\", \"year\" int(the year the movie came out), \"raw_dialogue\": \"All the words they say in the movie\", \"num_words\": int(the number of words they say in the movie)}]\n",
    "\"\"\"\n",
    "def read_scripts(movie_metadata, unacceptable_starters, punct_remover):\n",
    "\n",
    "    returner=[]\n",
    "\n",
    "    for movie_filename in movie_metadata:\n",
    "        path=os.path.join(\"data\", \"scripts\",\"Using\", movie_filename)\n",
    "        current_movie=movie_metadata[movie_filename]\n",
    "\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            movie_script=f.readlines()\n",
    "            start_of_content=False\n",
    "            this_movie_dicts=[]\n",
    "            current_character_dict={}\n",
    "            movie_title=movie_metadata[movie_filename]['title']\n",
    "            current_character_name=\"\" \n",
    "            year=int(current_movie['year'])\n",
    "            acceptable_characters=current_movie[\"characters\"]+current_movie['villain']      \n",
    "            \n",
    "            for line in movie_script:\n",
    "                line=line.strip()\n",
    "\n",
    "                #checks for the title and the first character, otherwise skips the header stuff\n",
    "                if not start_of_content:\n",
    "                    line=line.strip('\"')\n",
    "\n",
    "                    is_character, new_character_name = check_if_character(line, string.punctuation)\n",
    "\n",
    "                    if is_character and new_character_name not in unacceptable_starters and check_if_acceptable_character(new_character_name, acceptable_characters):\n",
    "                        start_of_content=True\n",
    "                        current_character_name=new_character_name\n",
    "                        current_character_dict={\"character\": current_character_name, \"movie_title\": movie_title, \"year\":year, \"is_villain\": False, \"raw_dialogue\":\"\"}\n",
    "                        if current_character_name in current_movie['villain']:\n",
    "                            current_character_dict['is_villain']=True\n",
    "                        this_movie_dicts.append(current_character_dict)\n",
    "                \n",
    "                #if in the middle of the script and you have a current character, check if this line is a new character otherwise add the dialogue to this character's list\n",
    "                else:\n",
    "                    is_new_character, new_character_name = check_if_character(line, string.punctuation)\n",
    "                    if is_new_character:\n",
    "                        current_character_name=new_character_name\n",
    "                        if current_character_name not in unacceptable_starters and check_if_acceptable_character(current_character_name, acceptable_characters):\n",
    "                            if current_character_name not in [entry['character'] for entry in this_movie_dicts]:\n",
    "                                current_character_dict={\"character\": current_character_name, \"movie_title\": movie_title, \"year\":year, \"is_villain\": False, \"raw_dialogue\":\"\"}\n",
    "                                if current_character_name in current_movie['villain']:\n",
    "                                    current_character_dict['is_villain']=True\n",
    "                                this_movie_dicts.append(current_character_dict)\n",
    "                            else:\n",
    "                                current_character_dict=[entry for entry in this_movie_dicts if entry['character']==current_character_name][0]\n",
    "                            \n",
    "                    else:\n",
    "                        if current_character_name in unacceptable_starters or not check_if_acceptable_character(current_character_name, acceptable_characters):\n",
    "                            pass\n",
    "                        else:\n",
    "                            if len(line)>0 and line[0]!='(' and line not in unacceptable_starters:\n",
    "                                current_character_dict['raw_dialogue']=current_character_dict['raw_dialogue'].strip()+' ' + line.translate(punct_remover).strip()\n",
    "\n",
    "            returner+=this_movie_dicts\n",
    "\n",
    "        \n",
    "    for entry in returner:\n",
    "        entry['num_words']=entry['raw_dialogue'].count(' ')+1\n",
    "    returner=[entry for entry in returner if entry['num_words']>50]    \n",
    "\n",
    "    return returner                            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A convenience function that adds all lines from character_name_to_remove to character_name_to_keep and then removes character_name_to_remove from the list. \n",
    "def combine_characters(movie_character_dict, movie_title, character_name_to_keep, character_name_to_remove):\n",
    "    movie_subset=[entry for entry in movie_character_dict if entry['movie_title']==movie_title]\n",
    "    if character_name_to_remove not in [entry['character'] for entry in movie_subset] or character_name_to_keep not in [entry['character'] for entry in movie_subset]:\n",
    "        return\n",
    "    to_remove=[entry for entry in movie_character_dict if entry['character']==character_name_to_remove][0]\n",
    "    keeper=[entry for entry in movie_subset if entry['character']==character_name_to_keep][0]\n",
    "    keeper['raw_dialogue']+=to_remove['raw_dialogue']\n",
    "    keeper['num_words']+=to_remove['num_words']\n",
    "    movie_character_dict.remove(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes the character with this character name from the list\n",
    "def remove_character(movie_character_dicts, character):\n",
    "    to_remove=[entry for entry in movie_character_dicts if entry['character']==character]\n",
    "    if len(to_remove)!=0:\n",
    "        movie_character_dicts.remove(to_remove[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a list of tokens, calculates a a mean emotional scoring of that list for each of the ten emotions present in the NRC Word-Emotion Association Emolex\n",
    "def add_emotion_scores(token_list, lexicon=None):\n",
    "    string_list=[token.text.lower().strip() for token in token_list]\n",
    "    re=[[],[],[],[],[],[],[],[],[],[]]\n",
    "    if lexicon==None:\n",
    "        lexicon=read_emolex()\n",
    "    for token in string_list:\n",
    "        if token in lexicon:\n",
    "            score_list=list(lexicon[token].values())\n",
    "            for score_index in range(len(score_list)):\n",
    "                re[score_index].append(score_list[score_index])\n",
    "    re=[score if len(score)>0 else [0] for score in re]\n",
    "    to_return = [np.mean(emotion) for emotion in re]\n",
    "    return to_return\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: Professor Wilkens, INFO 3350\n",
    "#convenience function to read the emotion lexicon into the variable emolex\n",
    "def read_emolex(filepath=None):\n",
    "    '''\n",
    "    Takes a file path to the emolex lexicon file.\n",
    "    Returns a dictionary of emolex sentiment values.\n",
    "    '''\n",
    "    if filepath==None: # Try to find the emolex file\n",
    "        filepath = os.path.join('data','emolex.txt')\n",
    "        if os.path.isfile(filepath):\n",
    "            pass\n",
    "        elif os.path.isfile('emolex.txt'):\n",
    "            filepath = 'emolex.txt'\n",
    "        else:\n",
    "            raise FileNotFoundError('No EmoLex file found')\n",
    "    emolex = defaultdict(dict) # Like Counter(), defaultdict eases dictionary creation\n",
    "    with open(filepath, 'r') as f:\n",
    "    # emolex file format is: word emotion value\n",
    "        for line in f:\n",
    "            word, emotion, value = line.strip().split()\n",
    "            emolex[word][emotion] = int(value)\n",
    "    return emolex\n",
    "\n",
    "# Get EmoLex data. Make sure you set the right file path above.\n",
    "emolex = read_emolex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a dataframe and a spacy nlp object, adds a column to the dataframe with an array of tokens present in each dialogue entry that aren't spaces, punctuation, or common stop words\n",
    "def tokenize(data_frame,nlp):\n",
    "    data_frame['token_list']=[[token for token in nlp(doc) if not (token.is_punct or token.is_space or token.is_stop)] for doc in data_frame['raw_dialogue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a list of tokens, calculate the mean embedding for all token in the list\n",
    "def add_embeddings(token_list, vector_length):\n",
    "    token_list=[token for token in token_list if token.has_vector]\n",
    "    doc_matrix=np.zeros([len(token_list), vector_length])\n",
    "    for i in range(len(doc_matrix)):\n",
    "        doc_matrix[i]=token_list[i].vector\n",
    "    return np.average(doc_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "amalgamated_dicts={}\n",
    "amalgamated_dicts.update(drama_movies)\n",
    "amalgamated_dicts.update(crime_movies)\n",
    "amalgamated_dicts.update(thriller_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unacceptable_starters=[\"VOICE (cont'd)\", \"VOICE (CONT'D)\", \"VOICE OVER (CONT'D)\", \"VOICE OVER (cont'd)\", \"DISSOLVE\", \"CUT\", \"CUT TO\", 'FADE', 'FADE OUT', 'FADE IN', 'PAN', 'CONTINUED', \"CONT'D\", '', ' ', \"VOICE\", \"VOICE OVER\", 'CUT TO', 'DISSOLVE TO', 'THE END', 'FADE TO BLACK', \"DISSOLVE TO:\", \"CUT TO:\", \"FADE TO:\"]\n",
    "\n",
    "punct_remover=str.maketrans('','', '\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~')\n",
    "\n",
    "movie_character_dicts=read_scripts(amalgamated_dicts, unacceptable_starters, punct_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random fixes\n",
    "\n",
    "combine_characters(movie_character_dicts, \"8MM\", \"AMY\", \"AMY'S VOICE\")\n",
    "combine_characters(movie_character_dicts, \"8mm\", \"DINO VELVET\", \"DINO\")\n",
    "combine_characters(movie_character_dicts, \"8mm\", \"DINO VELVET\", \"DINO VELVET VOICE\")\n",
    "combine_characters(movie_character_dicts, \"8mm\", \"WELLES\", \"WELLES VOICE\")\n",
    "combine_characters(movie_character_dicts, \"8mm\", \"WELLES\", \"WELLES' VOICE\")\n",
    "combine_characters(movie_character_dicts, \"MANHATTAN MURDER MYSTERIES\", \"HELEN\", \"HELEN'S VOICE\")\n",
    "combine_characters(movie_character_dicts, 'The Black Dahlia', \"CAPTAIN VASQUEZ\", 'VASQUEZ')\n",
    "combine_characters(movie_character_dicts, 'The Black Dahlia', \"JOHNNY VOGEL\", 'JOHNNY')\n",
    "combine_characters(movie_character_dicts, 'The Black Dahlia', \"JOHNNY VOGEL\", 'VOGEL')\n",
    "combine_characters(movie_character_dicts, \"The Black Dahlia\", \"LEE BLANCHARD\", \"LEE\")\n",
    "combine_characters(movie_character_dicts, \"The Black Dahlia\", \"Liz\", \"Elizabeth\")\n",
    "combine_characters(movie_character_dicts, 'The Black Dahlia', \"ELLIS LOEW\", 'LOEW')\n",
    "combine_characters(movie_character_dicts, 'The Black Dahlia', \"RUSS MILLARD\", 'MILLARD')\n",
    "combine_characters(movie_character_dicts, 'BASIC INSTINCT', \"CAPTAIN TALCOTT\", 'TALCOTT')\n",
    "combine_characters(movie_character_dicts, 'BASIC INSTINCT', \"CAPTAIN TALCOTT\", 'CAPT. TALCOTT')\n",
    "combine_characters(movie_character_dicts, 'Basic', \"DUNBAR\", 'DUN BAR')\n",
    "combine_characters(movie_character_dicts, 'Basic', \"MUELLER\", 'MUE:LLER')\n",
    "combine_characters(movie_character_dicts, 'Basic', \"OSBORNE\", 'OSB0RNE')\n",
    "combine_characters(movie_character_dicts, 'The Girl With ', \"GREGOR\", 'GREGER')\n",
    "combine_characters(movie_character_dicts, 'THE GIRL WITH THE DRAGON TATTOO', \"GREGOR\", 'GREGER')\n",
    "combine_characters(movie_character_dicts, 'THE GIRL WITH THE DRAGON TATTOO', \"BLOMKVIST\", 'BLOMVIST')\n",
    "combine_characters(movie_character_dicts, 'THE GIRL WITH THE DRAGON TATTOO', \"HARRIET\", 'HARRIE')\n",
    "combine_characters(movie_character_dicts, 'THE GIRL WITH THE DRAGON TATTOO', \"WENNERSTROM\", 'WENNERSTROM ON TV')\n",
    "combine_characters(movie_character_dicts, 'THE GIRL WITH THE DRAGON TATTOO', \"VANGER\", 'YOUNGER VANGER')\n",
    "combine_characters(movie_character_dicts, 'Insomnia', 'WALTER', \"WALTER'S VOICE\")\n",
    "combine_characters(movie_character_dicts, \"Blood Simple\", \"MARTY\", \"MARTY'S VOICE\")\n",
    "combine_characters(movie_character_dicts, \"Bonnie and Clyde\", \"BONNIE\", \"BONNIE'S VOICE\")\n",
    "combine_characters(movie_character_dicts, \"Twin Peaks\", \"BOBBY\", \"BOB'S VOICE\")\n",
    "combine_characters(movie_character_dicts, \"Klute\", \"TRASK\", \"TRASK'S VOICE\")\n",
    "combine_characters(movie_character_dicts, \"Klute\", \"CABLE\", \"CABLE'S VOICE\")\n",
    "combine_characters(movie_character_dicts, \"Brick\", \"LAURA\", \"LAURA'S VOICE\")\n",
    "combine_characters(movie_character_dicts, \"Brick\", \"BRENDAN\", \"BRENDAN'S VOICE\")\n",
    "combine_characters(movie_character_dicts, \"Charade\", \"REGGIE\", \"REGGIE'S VOICE\")\n",
    "combine_characters(movie_character_dicts, \"Copycat\", \"DARYLL LEE\", \"DARYLL\")\n",
    "combine_characters(movie_character_dicts, \"Sherlock Holmes\", \"SHERLOCK\", \"HOLMES\")\n",
    "combine_characters(movie_character_dicts, \"Crank\", \"Verona\", \"Erona\")\n",
    "combine_characters(movie_character_dicts, \"Blood Simple\", \"DOC MILES\", \"OC MILES\")\n",
    "combine_characters(movie_character_dicts, \"Devil in a Blue Dress\", \"ALBRIGHT\", \"ALBRIGHT'S VOICE\")\n",
    "combine_characters(movie_character_dicts, \"Blood Simple\", \"DAPHNE\", \"DAPHNE'S VOICE\")\n",
    "combine_characters(movie_character_dicts, \"Anonymous\", \"ELIZABETH\", \"YOUNG ELIZABETH\")\n",
    "combine_characters(movie_character_dicts, \"Anonymous\", \"OXFORD\", \"YOUNG OXFORD\")\n",
    "combine_characters(movie_character_dicts, \"Anonymous\", \"ROBERT CECIL\", \"BOY ROBERT CECILDAPHNE'S VOICE\")\n",
    "\n",
    "remove_character(movie_character_dicts, \"BONNY AND CLYDE\")\n",
    "remove_character(movie_character_dicts,\"I\")\n",
    "remove_character(movie_character_dicts, \"GRAMAM'S FEET\")\n",
    "remove_character(movie_character_dicts, \"HOLMES POV\")\n",
    "remove_character(movie_character_dicts, \"MRS. MULWRAY\")\n",
    "remove_character(movie_character_dicts,\"C\")\n",
    "remove_character(movie_character_dicts,\"S\")\n",
    "remove_character(movie_character_dicts,\"T\")\n",
    "remove_character(movie_character_dicts,\"H\")\n",
    "remove_character(movie_character_dicts,\"A\")\n",
    "remove_character(movie_character_dicts,\"I\")\n",
    "remove_character(movie_character_dicts,\"VE\")\n",
    "remove_character(movie_character_dicts,\"C\")\n",
    "remove_character(movie_character_dicts,\"DARKMAN\")\n",
    "remove_character(movie_character_dicts,\"161 PEYTON 161\")\n",
    "remove_character(movie_character_dicts,\"THE DAKMAN\")\n",
    "remove_character(movie_character_dicts,\"421 DARKMAN 421\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-17e8e19c41ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlocal_dataframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie_character_dicts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "local_dataframe=pd.DataFrame.from_dict(movie_character_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenize(local_dataframe, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 44.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_emotions = [add_emotion_scores(entry) for entry in local_dataframe['token_list']]\n",
    "local_dataframe['mean_anger'], local_dataframe['mean_anticipation'], local_dataframe['mean_disgust'], local_dataframe['mean_fear'], local_dataframe['mean_joy'], local_dataframe['mean_negative'], local_dataframe['mean_positive'], local_dataframe['mean_sadness'], local_dataframe['mean_surprise'], local_dataframe['mean_trust'] = np.flipud(np.rot90(all_emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 993 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vector_length=nlp.vocab.vectors_length\n",
    "local_dataframe['embeddings']=[add_embeddings(entry, vector_length) for entry in local_dataframe['token_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dataframe.to_csv(\"mystery_movie_data.csv\", index=False)"
   ]
  }
 ]
}